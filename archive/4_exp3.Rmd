---
output: bookdown::pdf_document2
---

```{r child = 'code/exp3_code.Rmd', cache = TRUE}
```

# Experiment 3: Investigating fine-grained perceptual changes from exposure to Spanish-accented stops

## Methods

The exposure phase was the same as Experiment 2, but the task used in the test phase was different.

### Design

To better detect subtle changes in perception as a function of exposure to Spanish-accented speech, we implemented the primed cross-modal lexical decision task from @xie2017similarity.
This design is illustrated in Figure \@ref(fig:exp3-fig).
We maintained the same three types of Target: Identity, Competitor, and Unrelated.
However, participants performed a different task with these targets relative to Experiment 2.
Specifically, participants decided whether the visual target was a real English word or not.
The auditory primes should increase or decrease RTs on the visual targets as a function of perceptual adaptation to Spanish-accented voiceless stops.

```{r exp3-fig, fig.cap = "Experiment 3 design.", dpi = 300}
knitr::include_graphics("/Users/hollyzaharchuk/Mirror/dissertation/14_final_diss/figures/diss_3.png")
```

### Participants {#methods-pars-2}

We recruited `r par_all[4]` participants through Prolific.
After removing ineligible participants, `r par_diff$elig_2[4]` remained.
After removing participants with poor data quality, `r par_qual[4]` remained for analysis (`r par_text$report[4]`)
All aspects of recruitment were the same as those described in Experiments 1 and 2.

A separate group of `r par_all[5]` participants was also recruited to complete the experiment without the exposure phase.
There were `r par_diff$elig_2[5]` participants remaining after checking the eligibility criteria, and `r par_qual[5]` participants remained after checking for data quality (`r par_text$report[5]`).

### Stimuli

The real words and pseudowords in the exposure task were the same as those in Experiment 2.
The auditory primes in the test task were also the same.
The only difference was in the visual targets.

The unrelated target for each filler prime (144) was replaced with a pseudoword with a different filler onset from the prime.
Potential pseudowords were downloaded from the ELP's set of normed pseudowords.
The best possible match was selected for each prime by (orthographic) vowel and number of letters.
Three additional pseudoword targets were selected for practice.

### Experimental lists

The experimental lists for the exposure task were the same as in Experiment 2.
Talker assignment was also counterbalanced the same way.

For the critical primes (72), the combinations of auditory prime and visual target were counterbalanced across participants in three experimental lists as in Experiment 2.
For the filler primes (144), perfect counterbalancing across these three lists was not possible, since three quarters of the filler items in each list (108) needed to have unrelated pseudoword targets.
Three sets of primes, divided evenly by onset, were rotated through the assignment of Identity or Unrelated (pseudoword) target as evenly as possible.
This resulted in 12 experimental lists for the test phase, one for each combination of critical prime-target pair (3) and talker assignment (4).

### Tasks and procedure

The headphone check, exposure task, and post-experiment questionnaire were the same as Experiment 2.
The procedure was also the same.
The only difference was in the structure of the test task.

The test phase featured the cross-modal primed lexical decision task from @xie2017similarity.
On each trial, participants first heard a real word (auditory prime) and then saw a real word or pseudoword written on the screen (visual target).
They indicated whether the visual target was a real English word or not by pressing the *d* or *k* key on their keyboard.
The real word response was mapped to the same key as in the exposure task.
Participants completed six practice trials followed by 216 main trials presented in random order.
Half of the practice trials (3) and half of the main trials (108) required real word responses.
All of the trials with critical primes (72) required real word responses.

### Analysis

The data processing, model fitting, and analysis approaches were the same as in Experiment 2.
Prior to analyzing exposure task performance for real words with experimental onsets, we removed responses with RTs less than 50 ms (*N* = `r dat_rem_exp$rem_1[3]`; `r dat_rem_exp$pct_1[3]`).
We then detected and removed outliers (*N* = `r dat_rem_exp$rem_2[3]`; `r dat_rem_exp$pct_2[3]`).
Prior to analyzing test task performance for critical prime-target pairs, we removed responses with RTs less than 50 ms (*N* = `r dat_rem_test$rem_1[3]`; `r dat_rem_test$pct_1[3]`).
We then detected and removed outliers (*N* = `r dat_rem_test$rem_2[3]`; `r dat_rem_test$pct_2[3]`).

## Results

### Exposure

For accuracy, there was a significant interaction between Variability and Word type (`r exp_acc_2_comp_2_form`), with higher accuracy on pseudowords in Variant groups (`r exp_acc_2_means_simple_var_non`) compared to Invariant groups (`r exp_acc_2_means_simple_invar_non`; `r exp_acc_2_cont_simple_non`).
We also conducted pairwise comparisons within each combination of Similarity and Word type and within each combination of Variability and Word type.
There were no significant effects of Variability or Similarity, respectively (*ps* > .05).
By-participant and estimated marginal means for these comparisons are shown in Figure \@ref(fig:exp2-exp-fig).

For RT, there was a significant three-way interaction among Variability, Similarity, and Word type (`r exp_rt_2_comp_3_form`).
The two-way interaction between Similarity and Word type was also significant (`r exp_rt_2_comp_2_form`).
To follow up on the three-way interaction, we analyzed the simple effects of Variability and Similarity.
None of the pairwise comparisons was significant (*ps* > .05; see Figure \@ref(fig:exp2-exp-fig)).

```{r exp2-exp-fig, fig.cap = "Experiment 3 exposure task performance. Left column presents boxplots with mean accuracy by participant. Right column presents half violin plots with reaction times for correct responses and dot plots with mean reaction times for correct responses by participant. Plots are overlaid with estimated marginal means and 95\\% confidence intervals.", dpi = 300}
knitr::include_graphics("sections/code/outputs/plot_exp_1a.png")
```

### First test analysis: Comparing the exposure groups to the Test-only group

We observed a significant interaction between Exposure and Target for accuracy (`r test_acc_2_comp_form`).
However, pairwise comparisons within each level of Target did not reveal any significant differences between the Test-only group and any of the exposure groups (*ps* > .05).
By-participant means and estimated marginal means are shown in Figure \@ref(fig:exp3-test-fig1).

We also observed a significant interaction between Exposure and Target for RTs (`r test_rt_2_comp_form`).
This interaction was driven by slower RTs on Competitor targets in the Direct-Invariant condition (`r test_rt_2_train_invsim`) than in the Test-only condition (`r test_rt_2_train_no`; `r test_rt_2_no_invsim`).
None of the other comparisons was significant (*ps* > .05).
Distributions, by-participant means, and estimated marginal means are shown in Figure \@ref(fig:exp3-test-fig1).
To investigate the differences between exposure conditions, we conducted the second set of analyses comparing the factors of Variability and Similarity.

```{r exp3-test-fig1, fig.cap = "Experiment 3 test task performance. Top row presents boxplots with mean accuracy by participant. Bottom row presents half violin plots with reaction times for correct responses and dot plots with mean reaction times for correct responses by participant. Plots are overlaid with estimated marginal means and 95\\% confidence intervals.", dpi = 300}
knitr::include_graphics("sections/code/outputs/plot_test_2.png")
```

### Second test analysis: Comparing the effects of Variability and Similarity

For accuracy, we observed significant two-way interactions between Variability and Target (`r test_acc_2a_comp_var_form`) and between Similarity and Target (`r test_acc_2a_comp_sim_form`).
We followed up on these interactions with separate pairwise comparisons for Variability and Similarity within each level of Target.
Within the Identity level of Target, Invariant exposure (`r test_acc_2a_invar_id`) was associated with higher accuracy than Variant exposure (`r test_acc_2a_var_id`; `r test_acc_2a_var_invar`).
Within the Competitor level of Target, Indirect exposure (`r test_acc_2a_indir_comp`) was associated with higher accuracy than Direct exposure (`r test_acc_2a_dir_comp`; `r test_acc_2a_dir_indir`).
There was no difference between levels of Variability within the Unrelated level of Target (*p* > .05).
None of the comparisons between levels of Similarity was significant (*ps* > .05).

For RT, we also observed significant two-way interactions between Variability and Target (`r test_rt_2a_comp_var_form`) and between Similarity and Target (`r test_rt_2a_comp_sim_form`).
We followed up on these interactions with separate pairwise comparisons for Variability and Similarity within each level of Target; however, the pairwise comparisons between levels of Variability or levels of Similarity were not significant (*ps* > .05).
To further probe the source of the interactions in the model, we conducted pairwise comparisons between Direct and Indirect exposure at each level of Target and Variability and between Variant and Invariant exposure at each level of Target and Similarity.
Within the Competitor level of Target and Direct level of Similarity, Invariant exposure yielded slower reaction times (`r test_rt_2a_mean_comp_dir_invar`) than Variant exposure (`r test_rt_2a_mean_comp_dir_var; test_rt_2a_comp_dir_varinvar`).

## Discussion

Experiment 3 followed up on the findings of Experiment 2 with a different test task.
Recall that in Experiment 2, we observed higher accuracy on Competitor targets in the Direct-Invariant group than in any of the other groups.
This difference, however, was only significant for the comparison with Indirect-Invariant training.
The Test-only group did not differ significantly from the exposure groups, limiting our interpretation of the effects of Variability and Similarity.
We posited that Direct-Invariant training reduced lexical competition between voiced and voiceless stops, thereby increasing correct rejection of Competitor targets as matches for the Spanish-accented auditory primes.
The matching task required participants to explicitly compare the visual target to the auditory prime.
In Experiment 3, we took a more implicit approach.
The priming task probed the extent to which the auditory prime activated the visual target.
In this way, we could investigate changes in the perception of Spanish-accented stops.

When we compared the four exposure conditions to the Test-only condition, we observed slower RTs for Competitor targets after Direct-Invariant exposure.
We interpret this reduction in speed as a reduction in lexical competition.
For example, consider the auditory prime *park* and the visual target *bark*, which are minimal pairs that differ only in the voicing of their onsets.
The more the onset of *park* is perceived as /b/, the more it will activate the target *bark*.
This increase in activation will facilitate the lexical decision for *bark*, resulting in faster RTs.
Our results suggest that, in the absence of exposure to Spanish-accented speech, Spanish-accented *park* was perceived **more** like *bark*.
By contrast, with Direct-Invariant exposure, Spanish-accented *park* was perceived **less** like *bark*.
This reduction in lexical competition after training suggests that talker-specific exposure to Spanish-accented /p/, /t/, and /k/ improved phonetic categorization of short lag VOTs.
Based on this evidence for talker-independent adaptation, we conducted analyses to distinguish the effects of Variability and Similarity.

Within the Direct conditions, Invariant exposure reduced lexical competition more than Variant exposure.
This effect was illustrated by significantly slower RTs on Competitor targets for the Direct-Invariant group than for the Direct-Variant group.
In the previous analysis, we also saw that the Direct-Invariant group was slower on Competitor targets than the Test-only group.
This suggests that the Test-only and Direct-Variant groups exhibited similar levels of *park*-*bark* priming, indexing increased activation of /b/ by Spanish-accented /p/.
This finding is striking, considering that the Direct-Variant group had the same amount of exposure to Spanish-accented /p/, /t/, and /k/ from the same talkers as the Direct-Invariant group.
We will interpret this effect of Variability more fully in Section \@ref(discuss-study1).
In short, we will argue that listeners were not able to develop robust talker-independent models during Variant exposure.
Because this level of organization is subject to listeners' use of indexical and social information [@kleinschmidt2019], we will investigate their perceptions of the test talkers in Section \@ref(corr-intro).

# Exploratory analyses 

## Correlation analysis {#corr-intro}

Having analyzed the task data, we now compare post-experiment questionnaire responses to test task performance.
Recall that the test task used in Experiments 1 and 2 was different from the one used in Experiment 3.
In both cases, performance on Competitor targets indexed lexical competition.
However, lexical competition had a different relation to performance depending on the task.
For the matching task, accuracy was a direct measure of competition between primes like *park* and targets like *bark*.
Differences in accuracy reflected differences in the activation of the onset competitor *bark*.
RT was less clearly related to differences in activation for competitors (since RT analyses were conducted on accurate responses).
By contrast, for the primed lexical decision task, RT was the clear measure of lexical competition, while accuracy was related more broadly to lexical activation.
Also recall that the test task used in Experiments 1 and 2 did not reveal significant differences between the Test-only and exposure groups.
Considering all of these factors, the correlation analysis presented here only includes the participants from Experiment 3, where we observed differential effects of exposure on test performance.

### Materials and analysis {#corr-mat}

Here we describe the post-experiment questionnaire items in detail.
The labels for the items in Figure \@ref(fig:exp3-corr-fig) are included in parentheses below.

First, participants answered questions related to the test talker's accent.
Participants indicated whether the talker had an accent or not, then rated the strength of the accent (Accent strength) and identified the type of accent.
For the type of accent, participants selected all that applied from the following options: city or region in the US; city or region outside the US; social, racial, or ethnic group; another language; and speech or language impairment.
Responses including the "another language" option were coded as 1/2, while responses that did not include this option were coded as -1/2 for analysis (Accent: L2).

Next, participants rated how well they understood the talker (Comprehensibility) and how easy it was to understand the talker (Ease).
They also identified the talker's L1 and proficiency in their L1 (L1 fluency).
Participants selected from the top 10 most spoken languages in the world [@ethnologue2024_2].
Spanish was coded as 1/2 and all other languages were coded as -1/2 (L1: Spanish).
Participants then identified whether the talker was bilingual or not; if so, they identified the talker's L2 and rated their proficiency (L2 fluency).
The same options were provided for identifying the talker's L2, with English coded as 1/2 and the remaining options coded as -1/2 (L2: English).

Finally, participants identified the talker's place of origin.
They began by selecting a global region---Africa, Americas, Asia, Europe, or Oceania---followed by a sub-region within the chosen region [@un2024].
If the Americas region was selected, participants were also able to select a specific country within their chosen sub-region.

For the correlations with task performance, we used average RT on Competitor targets as a measure of lexical competition (Competitor RT).
In the primed lexical decision task, RT was a direct measure of competition between minimal pairs, with differences in RT reflecting differences in activation of the onset competitor *bark*.
By contrast, accuracy was less clearly related to differences in activation for competitors, making this measure difficult to interpret in the context of a correlation analysis.
Thus, we did not include Competitor accuracy here.
We also coded participants in the Test-only group as -1/2 and participants in the exposure groups as 1/2 to measure general effects of exposure on test talker judgments (With/out exposure).

Pairwise correlations were calculated with the *psych* package [@revelle2023].
A Hommel correction was applied to the *p* values.

### Results

All pairwise correlations are illustrated in Figure \@ref(fig:exp3-corr-fig).
None of the questionnaire items correlated with performance on Competitor targets (*ps* > .05).

```{r exp3-corr-fig, fig.cap = "Experiment 3 correlation matrix between test performance and post-experiment questionnaire items.", dpi = 300}
knitr::include_graphics("sections/code/outputs/corr_plot_1.png")
```

### Discussion

Across participants in Experiment 3, we did not observe any correlations between participant judgments and test performance.
We also did not observe differences between participants who had completed the exposure phase and those who had not.
Within the context of listener perceptions of the talker, ratings of ease, comprehensibility, and accent strength patterned together.
Ease and comprehensibility were also strongly related to ratings of fluency in the L2.
Overall, lexical competition was not particularly sensitive to the social factors we measured.

## Talker analysis {#explore-spk}

Table \@ref(tab:spk-vot-tab) provides descriptive statistics of the VOT distributions for each talker by onset and phase.
Only the real words from the exposure phase are included in the distributions shown.

```{r spk-vot-tab}
avg_voice %>%
  kable(col.names = c("Phase", "Onset", "\\textit{N}", rep(c("\\textit{M}", "\\textit{SD}", "Range"), 4)),
        caption = "Mean, standard deviation, and range of VOTs by talker, onset, and phase.", 
        escape = FALSE) %>%
  kable_styling(bootstrap_options = "bordered", latex_options = "scale_down") %>%
  add_header_above(header = c(" " = 3, "Talker 1" = 3, "Talker 2" = 3, "Talker 3" = 3, "Talker 4" = 3)) %>%
  collapse_rows(columns = 1)
```

### Talker-specific analysis of voiceless stop VOT

We first investigate the extent to which each talker's voiceless stop VOTs diverge from L1 American English "norms," which represent our listeners' prior beliefs about these distributions.
We used the VOT dataset compiled by @chodroff2019 to determine the mean VOT for each voiceless stop onset among L1 American English talkers (see Table \@ref(tab:spk-vot-mu)).
We then conducted one-sample t-tests to compare each of the talkers' mean VOTs to the norm.
These analyses included both the exposure (multisyllabic) and test (monosyllabic) stimuli (48 items per onset per talker).
Table \@ref(tab:spk-vot-mu) provides the difference in means and asterisks indicating the significance level from each analysis (corrected for multiple comparisons with the Hommel method).

```{r spk-vot-mu}
tab_voice_mu %>%
  kable(caption = "Mean difference between L1 American English and talker mean VOTs by onset. Asterisks indicate significance levels from two-sample t-tests: *** < .001, ** < .01, * < .05. American English mean from Chodroff and Wilson (2019).", 
        escape = FALSE) %>%
  kable_styling(bootstrap_options = "bordered", latex_options = "scale_down") %>%
  collapse_rows(columns = 1)
```

### Between-talker comparison of voiceless stop VOT

We next investigate the extent to which each talker's mean VOTs differed from the other talkers'.
This analysis provides a point of comparison to Xie and Myers' (2017) operationalization of exposure-test similarity.
Here, we conducted two-sample t-tests on each pair of talkers by onset (48 items per onset per talker).
The difference between each pair of means, along with asterisks indicating the significance levels from these tests (corrected for multiple comparisons with the Hommel method), are provided in Table \@ref(tab:spk-vot-mat).
Figure \@ref(fig:ptk-vot-fig) visualizes the cue-category distributions for each talker and onset with respect to the L1 American English mean.

```{r spk-vot-mat}
matrix_voice %>%
  kable(caption = "Mean difference in VOT between talkers (row minus column) by onset. Asterisks indicate significance levels from two-sample t-tests: *** < .001, ** < .01, * < .05.", 
        escape = FALSE) %>%
  kable_styling(bootstrap_options = "bordered", latex_options = "scale_down") %>%
  collapse_rows(columns = 1)
```

```{r ptk-vot-fig, fig.cap = "Smoothed density estimates of VOT by talker and onset. Dotted lines represent L1 American English means from Chodroff and Wilson (2019).", dpi = 300}
knitr::include_graphics("sections/code/outputs/vot_ptk_plot.png")
```

### Discussion

The two analyses conducted in this section show that our talkers differed from both L1 American English norms and one another in their VOT distributions.
Talker 4 produced the most Spanish-like VOT distributions across places of articulation, with significantly shorter means in all comparisons.
Talker 3 also differed from the L1 American English norms and the three other talkers, but in the opposite direction: her mean VOTs were significantly longer in all comparisons.
Talkers 1 and 2 were the most similar to one another.
Talker 1 was the most similar to the L1 American English norms, though both she and Talker 2 had significantly longer /k/ VOTs.
Overall, each talker exhibited a different pattern of VOT-stop distributions.
The implications of these patterns for our results are discussed further in Section \@ref(discuss-sim).



