---
output: bookdown::pdf_document2
---

# Supplementary analyses 

## Correlation analysis

Having analyzed the task data, we now turn to the post-experiment questionnaire.
We were interested in the relations between a participant's perception of the test talkers and their performance on the test task.
To investigate these relations, we quantified the questionnaire responses and correlated them with overall task performance.
The labels for the items in Figure \@ref(fig:corr-fig) are included in parentheses next to their descriptions below.

### Post-experiment questionnaire {#corr-mat}

Here we describe the items in the questionnaire and how they were coded for analysis.
Items requiring ratings were collected on five-point scales anchored at the endpoints with labels containing the modifier "very" and a relevant adjective (e.g., "very weak" and "very strong" for accent strength).
Items requiring categorical responses were collected by presenting a relevant set of options to choose from (see below).
The options for these items were presented in alphabetical order.

#### Talker questionnaire items

Participants indicated whether the talker had an accent or not, then rated the strength of the accent (Talker accent strength) and identified the type of accent.
For the type of accent, participants selected all that applied from the following options: city or region in the US; city or region outside the US; social, racial, or ethnic group; another language; and speech or language impairment.

Next, participants rated how well they understood the talker (Talker comprehensibility) and how easy it was to understand the talker (Talker ease).
They also identified the talker's L1 and proficiency in their L1.
Participants selected from a list of the top 10 most spoken languages in the world [@ethnologue2024_2], as well as a "None of these" option.
Participants then indicated whether the talker knew a second language or not; if so, they identified the talker's L2 and rated their proficiency.
The same options for identifying the talker's L1 were provided for the L2.

Regarding the L1 and L2 proficiency ratings, we included whichever rating was provided for English (Talker English rating).
Regarding the first and second languages, we collapsed across the two responses and coded them according to typological distance from Spanish (Talker language accuracy).
Responses that only included English were coded as 0.
Otherwise, responses identifying either the L1 or L2 as Spanish were coded as 5, Portuguese as 4, French as 3, another Indo-European language (Urdu, Hindi, Bengali, or Russian) as 2, and a language from a different family (Mandarin, Standard Arabic, or Other) as 1.

Finally, participants identified the talker's place of origin.
They began by selecting a global region---Africa, Americas, Asia, Europe, or Oceania---followed by a sub-region within the chosen region [@un2024].
If the Americas region was selected, participants were also able to select a specific country within their chosen sub-region.
We coded responses by distance from the correct sub-region (Talker region accuracy), such that Americas-Central was 5, Americas-Northern was 4, Americas-Caribbean was 3, Americas-Southern was 2, Europe was 1, and all other responses were 0.

#### Participant questionnaire items

Participants indicated whether they had an accent or not, then rated the strength of the accent (Own accent strength) and identified the type of accent from the options described above.
To measure the overlap between a participant's perception of their own accent and their perception of the talker's accent, we divided the number of labels in common by the total number of unique labels from both responses (Own accent comparison).
For example, if a participant selected "social, racial, or ethnic group" for their own accent and "social, racial, or ethnic group" and "another language" for the talker's accent, their value would be 0.5 (i.e., 1 common label / 2 total unique labels).

In addition, participants identified their L1 and rated their proficiency.
They also indicated whether they knew a second language or not; if they responded "yes", they identified the L2 from the options described above and rated their proficiency.
Participants also identified their place of origin as described above and indicated whether they currently lived in this location or not.
At the end of the questionnaire, participants provided their age and indicated whether they had normal/corrected-to-normal vision or not, whether they had normal hearing or not, and whether they had a history of language disorders or not.

### Test task performance measures

We calculated two measures of test task performance.
First, we calculated d prime (d'), where hits were the correctly identified Identity targets and false alarms were the incorrectly identified Competitor targets.
The rates were calculated using the loglinear approach to handle extreme values of 1/0 [@hautus1995].
For Experiments 1 and 2, correct/incorrect identification meant matching the visual target with the auditory prime.
For Experiment 3, this meant making a lexical decision on the visual target.
To account for this discrepancy in the underlying task, we z-scored the hit and false alarm rates separately for the two test tasks (Test accuracy).
This procedure provided a task-neutral base from which to assign the ultimate d' scores across participants.
Second, we calculated the difference in mean reaction time between Competitor and Identity targets for accurate responses.
These differences were also z-scored separately for the two test tasks (Test RT).

### Analysis approach

All participants across the three experiments were included in the correlation analysis (*N* = `r sum(par_qual)`).
There were six measures related to the participant's perception of the talker's speech: Talker accent strength, Talker comprehensibility, Talker ease, Talker English rating, Talker language accuracy, and Talker region accuracy.
In addition, there was one measure related to the participants themselves---Own accented strength---and another at the intersection of participant and talker---Own accent comparison.
We also included Test accuracy and Test RT.
Pairwise correlations were calculated with the *psych* package [@revelle2023].
Hommel correctiona were applied to the *p* values.

### Results

All pairwise correlations are illustrated in Figure \@ref(fig:corr-fig).
Test accuracy was positively correlated with both Talker ease and Talker comprehensibility, such that a participant's d' increased as their perception of how easy it was to understand the talker increased (`r corr_ease_d`) and as their perception of how well they understood the talker increased (`r corr_comp_d`).
Talker ease and Talker comprehensibility were themselves positively correlated (`r corr_ease_comp`).

```{r corr-fig, fig.cap = "Cross-experiment correlation matrix comparing test task performance and post-experiment questionnaire items. Asterisks indicate significance levels: *** < .001, ** < .01, * < .05.", dpi = 300}
knitr::include_graphics("sections/code/outputs/corr_plot_1.png")
```

### Discussion

A participant's perceptions of the test talker's speech---Talker ease, comprehensibility, accent strength, and English rating---were strongly correlated with one another.
Talker accent strength was negatively correlated with the other three measures, such that higher (stronger) accent ratings were associated with lower ease, comprehensibility, and English ratings.
Of these four measures, Talker ease and comprehensibility were associated with actual task performance, albeit weakly.
Overall, these results suggest that high-level perceptions of a talker are related to low-level speech recognition.
However, intuitions about the source of a talker's accent---here, Mexican varieties of Spanish---did not correlate with test task d' scores or RTs.
To further investigate the relations between the subjective and objective performance measures, we conducted a second set of analyses.

## Exploratory analyses {#explore-follow}

The correlation analysis investigated the one-to-one relations between our test task and questionnaire measures.
Here, we follow up on this general analysis by considering the details of the test task.
Specifically, we were interested how perceptions of the test talker differed by individual talker, test task, and exposure.
We were also interested in how test task performance differed by talker.

### Analysis approach

Since Talker ease, comprehensibility, accent strength, and English ratings were highly correlated, we averaged across these four measures to create one score (Talker judgments).
Before averaging, Talker English rating was reverse-coded, such that "very strong" became 1 (rather than 5) and "very weak" became 5 (rather than 1), in order to align its valence with the other three measures.
We also averaged Talker language accuracy and region accuracy (Talker accuracy).

We ran two sets of linear models using the *stats* package [@rcore2022].
The first set modeled the interactions among Talker, Task, and Training on the two summary measures from the post-experiment questionnaire (Talker judgments and Talker accuracy).
The four levels of Talker (1, 2, 3, 4) were coded with Helmert contrasts.
The two levels of Task (Matching, LDT) and Training (Exposure, Test-only) were sum contrast-coded.
Participants from all three experiments were included in this set of analyses (*N* = `r sum(par_qual)`).
The second set modeled the interaction between Talker and Training on the two test task performance measures (Test accuracy and Test RT).
Because these measures were z-scored by task, we included the Task factor as a main effect only.
This second set of models also included Talker judgments and Talker accuracy as covariates.
We removed participants with z-scores above 4 or below -4 from each analysis, leaving `r num_prime` participants in the Test accuracy analysis and `r num_rt` participants in the Test RT analysis.

We used the *car* package to calculate Type-III analysis-of-variance tables and conduct chi-square tests [@fox2019].
We used the *emmeans* package to calculate estimated marginal means and conduct pairwise comparisons [@lenth2022].
Hommel adjustments were applied to the pairwise *p*-values.

### Results

In the Talker judgments analysis, we observed significant main effects of Talker (`r mod_spk_comp_speaker_form`) and Training (`r mod_spk_comp_train_form`).
The pairwise comparisons between talkers are shown in Figure \@ref(fig:explore-fig).
Participants in the Test-only group gave higher talker ratings (`r mod_train_without`) than participants in any of the exposure groups (`r mod_train_with`; `r mod_spk_cont_train`).
There were no main effects or interactions in the Talker accuracy analysis (*ps* > .05).

In the Test accuracy analysis, we observed a significant main effect of Talker (`r mod_prime_comp_speaker_form`).
The pairwise comparisons between talkers are shown in Figure \@ref(fig:explore-fig).
In addition, we observed a main effect of Talker judgments (`r mod_prime_beta_mean`, `r mod_prime_comp_mean_form`), with higher d' scores associated with higher ratings (as in the correlation analysis above).
There were no main effects or interactions in the Test RT analysis (*ps* > .05).

```{r explore-fig, fig.cap = "Participant ratings of test talker by talker (left panel) and test task d' by talker (right panel). Talker judgments are composite scores averaging across Talker ease, comprehensibility, English rating, and accent strength. Test accuracy is z-scored hit rate (percent correct Identity targets) minus z-scored false alarm rate (percent incorrect Competitor targets). Boxplots present scores by participant. Plots are overlaid with estimated marginal means and 95\\% confidence intervals. Asterisks indicate significance levels from pairwise comparisons: *** < .001, ** < .01, * < .05.", dpi = 300}
knitr::include_graphics("sections/code/outputs/plot_explore.png")
```

### Discussion

We followed up on the correlation analysis in the previous section by exploring the effects of talker, task, and training on participants' ratings of the test talker and task performance.
We observed differences between talkers in both Talker judgments and Test accuracy.
The strongest differences were between Talkers 1 and 4.
Specifically, Talker 1 had higher (more favorable) ratings from participants and yielded higher d' scores than Talker 4.
Talker 1 also yielded higher d' scores than Talkers 2 or 3.
In the next section, we investigate the acoustic-phonetic properties of the four talkers to interpret these results.

## Talker analyses {#explore-spk}

In the previous two sections, we established that a participant's perceptions of the test talker were associated with their task performance.
However, we have not yet investigated the performance of the test talkers themselves.
In this section, we compare the VOT distributions of the test talkers to better understand the relations among Talker judgments, Test accuracy, and talker-specific features.

### Talker-specific analysis of voiceless stop VOT

We first investigate the extent to which each talker's voiceless stop VOTs diverge from L1 US English "norms," which represent our listeners' prior beliefs about these distributions.
We used the VOT dataset compiled by @chodroff2019 to determine the mean VOT for each voiceless stop onset among L1 US English talkers (see Table \@ref(tab:spk-vot-mu)).
We then conducted one-sample t-tests to compare each of the talkers' mean VOTs to the norm.
These analyses included both the exposure (multisyllabic) and test (monosyllabic) stimuli (48 items per onset per talker).
Table \@ref(tab:spk-vot-mu) provides the difference in means and asterisks indicating the significance level from each analysis (corrected for multiple comparisons with the Hommel method).

```{r spk-vot-mu}
tab_voice_mu %>%
  kable(caption = "Mean difference between L1 US English and talker mean VOTs by onset. Asterisks indicate significance levels from two-sample t-tests: *** < .001, ** < .01, * < .05. English means from Chodroff and Wilson (2019).", 
        escape = FALSE) %>%
  kable_styling(bootstrap_options = "bordered", latex_options = "scale_down") %>%
  collapse_rows(columns = 1)
```

### Between-talker analysis of voiceless stop VOT

We next investigate the extent to which each talker's mean VOTs differed from the other talkers'.
This analysis provides a point of comparison to Xie and Myers' (2017) operationalization of exposure-test similarity.
Here, we conducted two-sample t-tests on each pair of talkers by onset (48 items per onset per talker).
The difference between each pair of means, along with asterisks indicating the significance levels from these tests (corrected for multiple comparisons with the Hommel method), are provided in Table \@ref(tab:spk-vot-mat).

```{r spk-vot-mat}
matrix_voice %>%
  kable(caption = "Mean difference in VOT between talkers (row minus column) by onset. Asterisks indicate significance levels from two-sample t-tests: *** < .001, ** < .01, * < .05.", 
        escape = FALSE) %>%
  kable_styling(bootstrap_options = "bordered", latex_options = "scale_down") %>%
  collapse_rows(columns = 1)
```

Figure \@ref(fig:ptk-vot-fig) visualizes the cue-category distributions for each talker and onset with respect to the L1 US English mean.

```{r ptk-vot-fig, fig.cap = "Smoothed density estimates of VOT by talker and onset. Dotted lines represent L1 US English means from Chodroff and Wilson (2019).", dpi = 300}
knitr::include_graphics("sections/code/outputs/vot_ptk_plot.png")
```

### Discussion

The three analyses conducted in this section show that our talkers differed from both L1 US English norms and one another in their VOT distributions.
Talker 4 produced the most Spanish-like VOT distributions across places of articulation, with significantly shorter means in all comparisons.
Talker 3 also differed from the L1 US English norms and the three other talkers, but in the opposite direction: her mean VOTs were significantly longer in all comparisons.
Talkers 1 and 2 were the most similar to one another.
Talker 1 was the most similar to the L1 US English norms, though both she and Talker 2 had significantly longer /k/ VOTs.
Overall, each talker exhibited a different pattern of VOT-stop distributions.
The implications of these patterns for our results are discussed further in Section \@ref(discuss-sim).



